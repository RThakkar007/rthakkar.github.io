**ISTQB® Advanced Level Test Manager certification (CTAL-TM)**


**Risk Mitigation**

1. Risk could be either avoided, mitigate or accepted.
2. 

**Risk Control**

**Risk Managment in the LifeCycle**
- Root Cause Analysis

**Lightweight Risk-based Approaches**


**Heavyweight Risk-based Approaches**
- Hazard analysis
- Cost of exposure
- FMEA - Failure Mode and Effects Analysis(FMEA)
- Qulity Fuction Deploment (QFD)
- Fault Tree Analysis(FTA)

**Stakeholder Involvement in Risk-based Testing**
1. Business stakeholders
2. Technical stakeholders


**In many cases, this involves answering some or all of the following 

**Four** questions through metrics and consultation with the team.

• Did the test team detect a greater percentage of important defects than of less-important defects?
• Did the test team find most of the important defects early in the test execution period?
• Was the test team able to explain the test results to stakeholders in terms of risk?
• Did the tests the test team skipped (if any) have alower level of associated risk than those executed?
In most cases, successful risk-based testing results in answering yes to all four questions.

Requirement Based Testing
1. Ambiguity Reviews
2. Test condition Analysis
3. Cause-effect Graphing
4. Model-based Testing

Metrics related to test coverage include:
• Requirements and design elements coverage
• Risk coverage
• Environment/configuration coverage
• Code coverage

Metrics to monitor test planning and control activities may include:

• Risk, requirements, and other test basis element coverage
• Defect discovery
• Planned versus actual hours to develop testware and execute test cases

Metrics to monitor test analysis activities may include:

• Number of test conditions identified
• Number of defects found during test analysis (For example, by identifying risks or other test conditions using the test basis)

Metrics to monitor test design activities may include:

• Percentage of test conditions covered by test cases
• Number of defects found during test design (For example, by developing tests against the test basis)

Metrics to monitor test implementation activities may include:

• Percentage of test environments configured
• Percentage of test data records loaded
• Percentage of test cases automated

Process or standard-complaince 

Reactive Strategies

Test Estimation: 


**Matrics Categorization :**

Metrics related to product risks include:

• Percentage of risks completely covered by passing tests
• Percentage of risks for which some or all tests fail
• Percentage of risk not yet completely tested
• Percentage of risks covered, sorted by risk category
• Percentage of risks identified after the initial quality risk analysis


Mtrics related to tests include:

• Breakdown of the number or percentage of defects categorized by the following:
o Particular test items or components: how many bugs per module or components
o Root causes
o Source of defect: how many bugs due to requirements defects vs design defects vs code defects
o Test releases
o Phase introduced, detected, and removed
o Priority/severity
o Reports rejected or duplicated
o Developer
o tester

Metrics related to tests include:

• Total number of tests planned, specified (implemented), run, passed, failed, blocked, and skipped
• Regression and confirmation test status, including trends and totals for regression test and confirmation test failures
• Hours of testing planned per day versus actual hours achieved
• Availability of the test environment (percentage of planned test hours when the test environment is usable by the test team)

Business Value Testing
Cost of Prevention
Cost of detection
Cost of internal failure
Cost of external failure

Distributed, Outsourced, and Insourced Testing
=> Roles and responsibilties
=> Cultural differnces

Mothodologies
=> Test efforts is the need for alignment of methodologies

Devision of test work

Trust

CMMI stands for capability maturity model
integration it includes two key proces ireas.
verification and validation, which are often interpreted as referring to levels
of testing (such as system testing and acceptance testing, respectively).
So system testing is verification and accebtance testing is validation.


**Management Reviews**

What Risks to cover during review Planning?
Even though reviews are beneficial, but we can’t review every single written document in our project, it will be cost ineffective and time consuming, so we need to decide what to review.

•For each work product reviewed, the following metrics
can be measured and reported for product evaluation.
Again, when you listen to the following metrics, remember that we are measuring
them to evaluate the product, to evaluate if the product is in good shape or not:

•	Work-product size
o	How many pages, or how many lines of code have been reviewed

•	Preparation time
o	How many minutes or hours were needed to get ready
for the review before the actual review meeting
•	Time to conduct the review
•	Rework time to fix defects
•	Duration of the whole review process
o	The longer the duration, could mean that the product is not in a good shape
•	Number of defects found and their severity
•	Identification of defect clusters within the work product
o	Which area in the reviewed document have a higher defect densitye

**Type of review**
Informal review, walkthrough, technical review or inspection.
This is to calculate review effectiveness to help choose the most effective type of reviews for this type of products in the future
•	Average defect density

For example, defects per page or per thousand lines of code
•	Estimated residual defects
o	Based on the defects found and the size of the reviewed item, we can
estimate the number of defects remaining from historical averages.
This will help us make good decisions about whether to declare
the review process completes for a given work product or not.


